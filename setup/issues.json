[
  {
    "title": "[AI] Casos de uso LLM na camada application",
    "labels": ["backend", "ai", "application"],
    "milestone_hint": "M2",
    "body": "Dependências: [AI] Provider OpenAI, [DB]\nObjetivo: Expôr serviços consistentes (`generatePlan`, `evaluateAnswer`, `interviewRubricEval`) na camada application.\nEscopo:\n- Implementar use cases orquestrando o `LLMProvider`\n- Padronizar DTOs/erros e logs estruturados\n- Garantir contratos para integração com BFF e UI\nCritérios de aceitação:\n- Casos de uso cobertos por testes unitários com mocks do provider\nEsforço: média"
  },
  {
    "title": "[Infra] Validar configuração OpenAI no runtime",
    "labels": ["backend", "infrastructure"],
    "milestone_hint": "M2",
    "body": "Dependências: [AI] Casos de uso LLM\nObjetivo: Garantir inicialização segura do provider OpenAI.\nEscopo:\n- Tornar `OPENAI_API_KEY` e `OPENAI_MODEL` obrigatórios quando IA estiver habilitada\n- Logs amigáveis na inicialização e quando indisponível\n- Documentar variáveis em README e `.env.example`\nCritérios de aceitação:\n- Aplicação aborta com mensagem clara se faltar configuração crítica\nEsforço: baixa"
  },
  {
    "title": "[API] Rotas BFF para serviços de IA",
    "labels": ["backend", "api", "ai"],
    "milestone_hint": "M2",
    "body": "Dependências: [AI] Casos de uso LLM, [Infra] Validar configuração OpenAI\nObjetivo: Expor endpoints server-side para plano, avaliação e chat.\nEscopo:\n- Criar rotas/server actions (`/api/ai/plan`, `/api/ai/assessment`, `/api/ai/chat`)\n- Tratamento de erros (timeouts, rate limit, auth)\n- Emissão de eventos de produto/observabilidade\nCritérios de aceitação:\n- Endpoints retornam JSON válido e lidam com falhas da OpenAI\nEsforço: média"
  },
  {
    "title": "[Docs] Atualizar OpenAPI com endpoints de IA",
    "labels": ["documentation", "api", "ai"],
    "milestone_hint": "M2",
    "body": "Dependências: [API] Rotas BFF para serviços de IA\nObjetivo: Manter Swagger alinhado às novas rotas de IA.\nEscopo:\n- Registrar schemas de request/response no `registry`\n- Atualizar página `/api-docs` e automatizar geração\n- Ajustar Spectral rules se necessário\nCritérios de aceitação:\n- `pnpm openapi:lint` passa e rotas aparecem no Swagger\nEsforço: baixa"
  },
  {
    "title": "[Tests] Cobrir o cliente OpenAI com mocks",
    "labels": ["quality", "ai", "backend"],
    "milestone_hint": "M2",
    "body": "Dependências: [AI] Casos de uso LLM\nObjetivo: Garantir resiliência do adapter OpenAI.\nEscopo:\n- Criar testes Vitest usando MSW ou fetch mockando respostas\n- Cobrir happy path, erros HTTP, timeouts e aborts\n- Validar mapeamento de JSON/schema\nCritérios de aceitação:\n- Cobertura mínima 80% no arquivo do provider OpenAI\nEsforço: média"
  },
  {
    "title": "[DB] Modelo AssessmentSession e respostas",
    "labels": ["database", "assessment", "backend"],
    "milestone_hint": "M2",
    "body": "Dependências: [DB] base, [Assessment] fluxos\nObjetivo: Persistir tentativas e diagnósticos de nivelamento.\nEscopo:\n- Criar tabelas `AssessmentSession`, `AssessmentAnswer`, `AssessmentResult`\n- Migrações Prisma + seed mínimo\n- Índices para consultas por usuário/data\nCritérios de aceitação:\n- Prisma client atualizado e consultas básicas funcionando\nEsforço: média"
  },
  {
    "title": "[Domínio] Entidades de nivelamento e diagnósticos",
    "labels": ["domain", "assessment", "ddd"],
    "milestone_hint": "M2",
    "body": "Dependências: [DB] Modelo AssessmentSession\nObjetivo: Formalizar objetos de domínio do assessment.\nEscopo:\n- Value Objects para questões, critérios e CEFR\n- Validações (pesos, limites, interpretações)\n- Conversões para DTOs consumidos pela aplicação\nCritérios de aceitação:\n- Tipos seguros reutilizados em casos de uso e UI\nEsforço: média"
  },
  {
    "title": "[Application] Orquestrar fluxo completo de assessment",
    "labels": ["backend", "assessment", "application"],
    "milestone_hint": "M2",
    "body": "Dependências: [Domínio] Entidades de nivelamento, [AI] Casos de uso LLM, [AI] ASR\nObjetivo: Implementar casos de uso para iniciar, registrar e finalizar o teste.\nEscopo:\n- Métodos para Start/Submit/Finalize com persistência\n- Integração com LLM/ASR e atualização do usuário\n- Emissão de eventos de retenção\nCritérios de aceitação:\n- Testes de integração cobrindo fluxo feliz e falhas de IA\nEsforço: alta"
  },
  {
    "title": "[Frontend] Nivelamento consumindo backend",
    "labels": ["frontend", "assessment", "ux"],
    "milestone_hint": "M2",
    "body": "Dependências: [API] Rotas BFF para serviços de IA, [Application] Orquestrar fluxo completo de assessment\nObjetivo: Refatorar UI do teste para usar dados reais.\nEscopo:\n- Buscar perguntas e progresso via API\n- Enviar respostas (MCQ, listening, speaking) e lidar com loading/erros\n- Mostrar resultado consolidado retornado pelo backend\nCritérios de aceitação:\n- Fluxo end-to-end funciona em dev com IA habilitada\nEsforço: alta"
  },
  {
    "title": "[Dashboard] Exibir nível e diagnóstico reais",
    "labels": ["frontend", "assessment", "dashboard"],
    "milestone_hint": "M3",
    "body": "Dependências: [DB] Modelo AssessmentSession, [Frontend] Nivelamento consumindo backend\nObjetivo: Reagir ao resultado do teste na área logada.\nEscopo:\n- Carregar dados do usuário/logado no BFF\n- Exibir forças, fraquezas e nível sugerido\n- Atualizar estudo/plano inicial conforme diagnóstico\nCritérios de aceitação:\n- Usuário recém-testado vê informação persistida no dashboard\nEsforço: média"
  },
  {
    "title": "[AI] Integração ASR para speaking curto",
    "labels": ["backend", "ai", "assessment"],
    "milestone_hint": "M2",
    "body": "Dependências: [Storage], [Application] Orquestrar fluxo completo de assessment\nObjetivo: Transcrever áudios do teste de speaking.\nEscopo:\n- Escolher provider (OpenAI Whisper ou similar)\n- Implementar adapter e testes de contrato\n- Endpoint upload + transcrição com métricas de duração\nCritérios de aceitação:\n- Retorna transcrição e metadados em até 30s\nEsforço: alta"
  },
  {
    "title": "[Observabilidade] Métricas e logs das chamadas de IA",
    "labels": ["observability", "ai", "backend"],
    "milestone_hint": "M2",
    "body": "Dependências: [API] Rotas BFF para serviços de IA\nObjetivo: Instrumentar chamadas LLM/ASR.\nEscopo:\n- Registrar latência, contadores de erro e requestId\n- Dashboard de métricas básicas (p95, p99)\n- Alertas simples em caso de falhas recorrentes\nCritérios de aceitação:\n- Health check expõe métricas IA e logs contêm contexto\nEsforço: média"
  },
  {
    "title": "[UX] Fallback quando IA estiver indisponível",
    "labels": ["frontend", "ux", "ai"],
    "milestone_hint": "M2",
    "body": "Dependências: [Frontend] Nivelamento consumindo backend, [API] Rotas BFF para serviços de IA\nObjetivo: Garantir experiência degradada amigável.\nEscopo:\n- Feature flag ou checagem de `hasLLMEnvironment`\n- Mensagens claras e desabilitar ações dependentes de IA\n- Telemetria registrando uso do fallback\nCritérios de aceitação:\n- Usuário recebe feedback imediato se IA estiver desligada\nEsforço: média"
  }
]
